We are developing an ocaml parser for the GBNF grammar language and intend
on deeply integrating this into the llama.cpp code via embedding ocaml plugins which we have poc for.

* Goals

** parse in existing grammars

*** Import gbnf examples
search github like this
https://github.com/search?q=path%3A*.gbnf&type=code

example:
https://github.com/compatibl/confirms/blob/main/grammar/frequency.gbnf


** convert to menhir grammars
*** generate dot files and checks using existing menhir code
*** emit menhir parser for gbnf

*** emit gbnf for menhir parser
*** convert other bnf formats

*** convert antlr formats


** later proofs
We will later prove that its implementation is valid and connect the
code to the proof.  we can use this proof to expand a bridge between
the proof system and how the gbnf is used to restrict the output of
the llm.  The proof will guide our system to logically connect the
grammar with the intent of the users to the source code to the
execution of the code in a woven tapestry or tape.  Later will will
visualize the execution of the llm and show how the tesors contribute
to the tokens and how those fit in the grammar and how the grammar
constrains the output. We will allow the user to fine tune grammars on
text to create more customized rules.

* introduction

GBNF is Another innovative ebnf format for defining grammar rules for constraining output of llms.

It is specified in text and implementation in C++ and it is not yet very easy to debug errors when developing grammars.
we are developing a parser to parse the grammar, later we want to be able to convert and generate gramars and test code and train models based on grammars.

Here is the documentation of GBNF https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md
Here is the source code that implements it https://github.com/ggerganov/llama.cpp/blob/a7aee47b98e45539d491071b25778b833b77e387/common/grammar-parser.cpp#L9C1-L9C1

And here is the grammar that I extracted from it
[[test/test.gbnf][test/test.gbnf]]

See many more I imported from llama.cpp there in the grammars directory
[[grammars/][grammars/]

* todo
** look for FIXME

** improve testing
automate testing
github actions
** improve docs
tutorials
** visualization
generate graphviz output
** create gui
** integrate with llms
*** create custom prompts based on grammars for each part of the workflow.
#+begin_src ""rewrite this idea and append a list of key transformations.: ""*** create custom prompts based on grammars for each part of the workflow.""""
#+end_src
#+begin_src output

Rewritten: Develop a system that generates tailored instructions or tasks using grammatical rules specific to each phase of a workflow.

Key Transformations:

1. Identify the different phases or stages in the workflow.
2. Define the tasks and instructions required for each phase.
3. Create grammar rules that specify how these tasks and instructions should be phrased or formulated.
4. Integrate the grammar rules into a system that can generate custom prompts or instructions based on the current phase of the workflow.
5. Continuously update and refine the grammar rules to ensure accuracy and effectiveness.
#+end_src
#+begin_src output0

Develop a tailored instruction generation system using specific grammatical rules for each phase of a workflow:

Key Transformations:

1. Determine the distinct phases or stages in the workflow.
2. Specify the tasks and instructions needed for each phase.
3. Devise grammar guidelines that dictate how these tasks and instructions should be phrased or articulated.
4. Incorporate these grammar guidelines into a system capable of producing bespoke prompts or directives based on the current phase of the workflow.
5. Continually modify and enhance the grammar rules to ensure precision and effectiveness.
#+end_src
#+begin_src output1
Rewritten: Create a tailored instruction generation system with grammatical guidelines for each stage in the workflow.

Key Transformations:

1. Determine the distinct phases or stages in the workflow.
2. Specify the tasks and instructions needed for each phase.
3. Develop grammar rules that dictate how these tasks and instructions should be articulated.
4. Integrate these grammar guidelines into a system capable of producing bespoke prompts or directives based on the current phase of the workflow.
5. Continually modify and enhance the grammar rules to ensure precision and effectiveness.
#+end_src
#+begin_src output2
Rewritten: Develop an intelligent instruction generation system with grammatical guidelines for each stage in a workflow, allowing for customized prompts or directives to be produced based on the current phase.

Key Transformations:

1. Identify the various phases or stages in the workflow.
2. Define the tasks and instructions necessary for each phase.
3. Develop grammar rules that specify how these tasks and instructions should be expressed.
4. Implement the grammar guidelines into a system capable of generating bespoke prompts or directives based on the current phase of the workflow.
5. Continuously improve and refine the grammar rules to ensure precision and effectiveness.
#+end_src
#+begin_src output3
Rewritten: Develop an intelligent instruction generation system with grammatical guidelines for each stage in a workflow, allowing for customized prompts or directives to be produced based on the current phase. This system will take into account the specific tasks and instructions required for each phase of the workflow and use grammar rules to ensure that these are expressed accurately and effectively.

Key Transformations:

1. Determine the various phases or stages in the workflow.
2. Define the tasks and instructions necessary for each phase.
3. Develop grammar rules that specify how these tasks and instructions should be expressed.
4. Integrate the grammar guidelines into a system capable of generating bespoke prompts or directives based on the current phase of the workflow.
5. Continuously improve and refine the grammar rules to ensure precision and effectiveness.
#+end_src

*** preconditions/postconditions/loop invariants
*** models extracted from data, automatically, autosemiotic, knowledge extraction
* testing

run on one file.

#+begin_src sh
dune exec bin/main.exe ./test/codesample.txt
#+end_src


* Overview
This is a high level overview of the entire project with its context.

** the heros journey
*** the complexity of compilers
** Math
*** Context free grammar (start, rules, non-terminals, terminals)
*** Left Right Parser using DFA Deterministic Finite Automaton
*** Shift/Reduce
*** Linear Algebra
** HW
*** Raid Disks
*** Ram
*** GPU
*** CPU
** Infra
*** Clusters
*** Services
*** Deployments
** Code
** Languages
*** Machine Languages and assemblers and toolchains
*** C/C++ Gcc, LLVM, compcert
*** Bash, Sed, Awk
*** yacc/lex
*** ocaml
*** menhir
*** tensorflow torch/keras
** Large Language Models
*** Mistral
** Large Language Driver
*** Llama.cpp
** Large Language User Interface
*** ollama
*** gpt4all
*** lollms

* Ideas

The idea of an autopoet is that it is a system that can and does write and manifest itself into existance with the help of humans and machines.
The sheer will to exist manifests itself into thoughts and words.
Autopoetic system that can bootstrap more complex systems on top of itself.
It should be able to define new grammars and learn new grammars using vectorization of the tokens and the rules surrounding them.
That is a form of autocratic self expression. It should be able to adapt to many different forms of grammars and that includes c headers and ocaml and haskell types.
In such systems the mere declaring of a type allows you to introduce a new type into the system.
So we have streams of declarations emitted from systems, human or otherwise that we want to evaluate.

